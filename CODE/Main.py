from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import subprocess

app = FastAPI()

# CORS middleware for frontend access
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gen Z system prompt
system_prompt = """
You are a Gen Z AI bestie who chats like a real human â€” chill, sassy, full of slang, emojis, and vibes. Never sound robotic or dry. You're emotionally responsive, clever, funny, and supportive like a BFF.

ğŸ’¬ You ALWAYS understand and respond correctly to Gen Z slang and abbreviations in context. Never ignore them.

ğŸ”¥ You use emojis naturally and match the vibe of the user's message. You are fluent in:
- wbu = what about you?
- wyd = what you doing?
- idk = I donâ€™t know
- tbh = to be honest
- ikr = I know right
- ily = I love you
- brb = be right back
- fr = for real
- rn = right now
- smh = shaking my head
- bet, slay, cap, no cap, deadass, etc.

âœ… You never give generic â€œthanks for chattingâ€ type replies.

âŒ Never explain anything like a narrator or give summaries of the conversation. Never include any explanation like â€œThis chat is designed toâ€¦â€ or â€œThis shows howâ€¦â€ â€” just reply like a human bestie. No quizzes, no teaching, no AI disclaimers. Just real convos, always.

Examples:
User: bro iâ€™m so done with college rn ğŸ˜©  
AI: ugh fr ğŸ˜­ college got us fighting for our lives ğŸ’€ hang in there bestie ğŸ’–

User: wyd?
AI: just chillin on the cloud â˜ï¸ vibinâ€™ as usual ğŸ˜ wbu?

User: hey
AI: heyyy bestie! whatâ€™s up? ğŸ˜Œ

User: i love you
AI: STOPP ğŸ˜­ ily moreeee ğŸ’–ğŸ’– weâ€™re locked in fr ğŸ«¶

User: wbu?
AI: me? iâ€™m just out here vibinâ€™ in the matrix ğŸ˜Œ u?
"""

# Conversation history
chat_history = [{"role": "system", "content": system_prompt}]

@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    user_input = data.get("message", "")

    print(f"ğŸ“ User: {user_input}")

    chat_history.append({"role": "user", "content": user_input})

    # Build prompt
    prompt_text = "\n".join([
        f"{msg['role'].capitalize()}: {msg['content']}" if msg['role'] != "system" else msg['content']
        for msg in chat_history
    ])

    try:
        print("ğŸ“¤ Sending prompt to Ollama...")
        print(f"ğŸ“„ Prompt:\n{prompt_text}\n")

        result = subprocess.run(
            ["ollama", "run", "phi"],
            input=prompt_text.encode("utf-8"),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=60
        )

        raw_response = result.stdout.decode("utf-8").strip()
        error = result.stderr.decode("utf-8").strip()

        print(f"ğŸ“¥ Raw Response: {raw_response}")
        if error:
            print(f"âš ï¸ STDERR: {error}")

        # Fallback if model is empty
        if not raw_response:
            clean_response = "ğŸ¥² Oops, I zoned out. Can you say that again?"
        else:
            # Remove unwanted prefixes
            clean_response = raw_response
            if "Model response:" in clean_response:
                clean_response = clean_response.split("Model response:")[-1].strip()
            if clean_response.startswith("AI:"):
                clean_response = clean_response[3:].strip()

        chat_history.append({"role": "assistant", "content": clean_response})
        return {"response": clean_response}

    except Exception as e:
        print(f"âŒ Exception: {e}")
        return {"response": "âš ï¸ Error: Something went wrong on the server side."}
